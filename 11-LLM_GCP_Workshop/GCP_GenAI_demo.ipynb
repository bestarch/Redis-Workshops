{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HqRohfRRZgFWtj1zYJIyvR5n",
   "metadata": {
    "id": "HqRohfRRZgFWtj1zYJIyvR5n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install required libraries\n",
    "!python3 -m pip -q install redis\n",
    "!pip install -U langchain gradio\n",
    "!pip install langchain-community \"unstructured[pdf]\"\n",
    "!pip install -U langchain-google-vertexai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1zTK0KXJUwzX",
   "metadata": {
    "id": "1zTK0KXJUwzX"
   },
   "outputs": [],
   "source": [
    "## Uncomment & execute the following code in case Redis Enterprise is not available\n",
    "##################################################################################\n",
    "\n",
    "# %%sh\n",
    "# curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "# echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "# sudo apt-get update  > /dev/null 2>&1\n",
    "# sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
    "# redis-stack-server --daemonize yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sjUooyI9VlAu",
   "metadata": {
    "id": "sjUooyI9VlAu"
   },
   "outputs": [],
   "source": [
    "## Update the 'host' field with the correct Redis host URL\n",
    "host = ''\n",
    "port =\n",
    "password = ''\n",
    "requirePass = True\n",
    "\n",
    "## For redis-stack-server, comment out the above code and uncomment the following:\n",
    "# host = 'localhost'\n",
    "# requirePass = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4UnZUjIFVxWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UnZUjIFVxWA",
    "outputId": "e836f647-883e-4a9e-b303-f55b935d899e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "if requirePass:\n",
    "    client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
    "else:\n",
    "    client = redis.Redis(host = 'localhost', decode_responses=True)\n",
    "\n",
    "print(client.ping())\n",
    "# Clear Redis database (optional)\n",
    "client.flushdb()\n",
    "\n",
    "REDIS_URL = f\"redis://:{password}@{host}:{port}\"\n",
    "INDEX_NAME = f\"idx_qna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_38Ye7niWPZR",
   "metadata": {
    "id": "_38Ye7niWPZR"
   },
   "outputs": [],
   "source": [
    "## Authenticate with GCP & set project id and region\n",
    "from google.colab import auth\n",
    "from getpass import getpass\n",
    "\n",
    "auth.authenticate_user()\n",
    "print('Authenticated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aeac21-5227-403b-87fd-bfdbc53977f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch your GCP project ID and region for Vertex AI\n",
    "import os\n",
    "\n",
    "# Get the default cloud project id.\n",
    "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
    "\n",
    "# Get the default region for launching jobs.\n",
    "REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnEl0UcxWV5w",
   "metadata": {
    "id": "cnEl0UcxWV5w"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/abhi-data-2024/how_india_shops_online.pdf -O report.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "-B_EHwP7ouXf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-B_EHwP7ouXf",
    "outputId": "ed7aff69-61a7-403d-da1b-ca5da113f18f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed and created 42 chunks of the original pdf report.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "\n",
    "doc = \"report.pdf\"\n",
    "\n",
    "# set up the file loader/extractor and text splitter to create chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "loader = UnstructuredPDFLoader(doc)\n",
    "\n",
    "# extract, load, and make chunks\n",
    "chunks = loader.load_and_split(text_splitter)\n",
    "print(\"Preprocessing completed and created\", len(chunks), \"chunks of the original pdf\", doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hKHXwtSGwNPr",
   "metadata": {
    "id": "hKHXwtSGwNPr"
   },
   "source": [
    "# Create text embeddings with Vertex AI embedding model\n",
    "\n",
    "Use the Vertex AI API for text embeddings, developed by Google.\n",
    "\n",
    "Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
    "\n",
    "\n",
    "*   Semantic search: Search text ranked by semantic similarity.\n",
    "*   Recommendation: Return items with text attributes similar to the given text.\n",
    "*   Classification: Return the class of items whose text attributes are similar to the given text.\n",
    "*   Clustering: Cluster items whose text attributes are similar to the given text.\n",
    "*   Outlier Detection: Return items where text attributes are least related to the given text.\n",
    "\n",
    "The Vertex AI text-embeddings API lets you create a text embedding using Generative AI on Vertex AI. The textembedding-gecko model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "A6H_vHkrSxco",
   "metadata": {
    "id": "A6H_vHkrSxco"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores.redis import Redis\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@003\", project=PROJECT_ID, location=REGION)\n",
    "\n",
    "def get_vectordb() -> Redis:\n",
    "    \"\"\"Create the Redis vectordb.\"\"\"\n",
    "\n",
    "    try:\n",
    "        vectordb = Redis.from_existing_index(\n",
    "            embedding=embeddings,\n",
    "            index_name=INDEX_NAME,\n",
    "            redis_url=REDIS_URL\n",
    "        )\n",
    "        return vectordb\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Load Redis with documents\n",
    "    vectordb = Redis.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        index_name=INDEX_NAME,\n",
    "        redis_url=REDIS_URL\n",
    "    )\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "redis = get_vectordb()\n",
    "\n",
    "#embedder = HuggingFaceEmbeddings(model_name=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kVJdyD1OVYE-",
   "metadata": {
    "id": "kVJdyD1OVYE-"
   },
   "source": [
    "# Include RAG\n",
    "\n",
    "We're going to build a complete RAG pipeline from scratch incorporating the following components:\n",
    "\n",
    "Standard retrieval and chat completion\n",
    "Dense content representation to improve accuracy\n",
    "Query re-writing to improve accuracy\n",
    "Semantic caching to improve performance\n",
    "Conversational session history to improve personalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aNtLTGcvR-IS",
   "metadata": {
    "id": "aNtLTGcvR-IS"
   },
   "source": [
    "### Define Prompt template\n",
    "PromptTemplate defines the exect text of the response that would be fed to the LLM. This step is optional, but the defaults usually work well for OpenAI and might fall short for other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "BCtEFE8ziT5d",
   "metadata": {
    "id": "BCtEFE8ziT5d"
   },
   "outputs": [],
   "source": [
    "#@title Function to define prompt template\n",
    "\n",
    "def create_prompt():\n",
    "    \"\"\"Create the QA chain.\"\"\"\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    from langchain.chains import RetrievalQA\n",
    "\n",
    "    # Define our prompt\n",
    "    prompt_template = \"\"\"Use only the following pieces of context to answer the question. If you don't know the answer, say that you don't know, don't try to make up an answer.\n",
    "\n",
    "    This should be in the following format:\n",
    "\n",
    "    Question: [question here]\n",
    "    Answer: [answer here]\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Context:\n",
    "    ---------\n",
    "    {context}\n",
    "    ---------\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "DYtdUxxFSxh9",
   "metadata": {
    "id": "DYtdUxxFSxh9"
   },
   "outputs": [],
   "source": [
    "#@title Invoke Google Vertex LLM using Langchain\n",
    "# This is where the Langchain brings all the components together in a form of a simple QnA chain\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=\"gemini-1.5-pro-preview-0409\",\n",
    "    max_output_tokens=2048,\n",
    "    temperature=0.5,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=redis.as_retriever(search_type=\"similarity_distance_threshold\",search_kwargs={\"distance_threshold\":0.5}),\n",
    "    #return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": create_prompt()},\n",
    "    #verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "XelSUbTkS7rj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "XelSUbTkS7rj",
    "outputId": "c2cb5b00-3b6c-4bd2-9219-390cceadf0dc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Question: What are some motivations for shopping online?\\nAnswer: Some motivations for shopping online include wider range of price options, wider range of brands available, the absence of physical stores for premium brands, stockouts of certain products, a lack of knowledgeable staff in offline stores, lack of discounts and special offers in physical stores, and large crowds in malls during weekends. \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('What are some motivations for shopping online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "B2f9CC3JI2BL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "B2f9CC3JI2BL",
    "outputId": "596e014e-ffce-4ac7-e5b2-8c25dc8e7411"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Question: How do Indians like to pay for shopping online?\\nAnswer: Indians both in urban and other areas are increasingly using UPI payments. However, cash on delivery is still preferred, especially outside of major cities.  Many people use cards for higher-priced items on familiar sites because they feel it's more secure. \\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('How do Indians like to pay for shopping online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "LLHoWVshJJHK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "LLHoWVshJJHK",
    "outputId": "005fd229-1257-4e8d-9696-56ca5e42ee61"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Question: What are some known challenges in shopping online?\\nAnswer: Some known challenges of shopping online include worrying about online payments and if products will arrive, not being sure what a product will look like in person based on a picture, and longer delivery times. \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('What are some known challenges in shopping online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5PVFYBW1NNKm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "5PVFYBW1NNKm",
    "outputId": "46749ae4-cee8-4c9e-a1c3-f79a610f41bf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Question: How home and kitchen segment is growing?\\nAnswer: In the Indian market, the home furnishing and kitchen sector has experienced remarkable growth and is growing at a CAGR of 10%. Several factors contribute to this growth including the countryâ€™s urbanisation, a substantial young population and the increasing aspirations of the burgeoning middle class. \\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('How home and kitchen segment is growing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bgfyRlzCNquj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "bgfyRlzCNquj",
    "outputId": "fc574a0b-0213-4ccb-d67d-c4e5f9bf329d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Question: What are the effects of social media on online shopping?\\nAnswer: Social media has amplified the awareness and aspirations and 62% of respondents tried products after seeing them (perhaps repeatedly) on Facebook and Instagram. As the preferences of rest of India shifts from TV and radio to digital avenues, social media becomes the most preferred channel for encouraging trials of new products. Interestingly, amongst urban dwellers, online communities lead to more trial than TV. WhatsApp, YouTube and Instagram have a universal appeal and are the most preferred social media platforms for urban dwellers and rest of India. \\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('What are the effects of social media on online shopping?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "xClDk__XHFw-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "xClDk__XHFw-",
    "outputId": "8450c20a-462f-450b-e529-28fa34454453"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Question: What are some relevant items that are shopped online?\\nAnswer: The text lists fashion and accessories, home and kitchen, beauty and personal care, health and wellness, sports and fitness, electronics and consumer durables, and groceries. \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run('What are some relevant items that are shopped online?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UmsYlwP9XZ2G",
   "metadata": {
    "id": "UmsYlwP9XZ2G"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def handle(query):\n",
    "    response = qa.run(query)\n",
    "    return response\n",
    "\n",
    "iface = gr.Interface(fn=handle, inputs=\"text\", outputs=\"text\")\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nvmnrq_3YY6p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvmnrq_3YY6p",
    "outputId": "2eecf130-23be-4791-e8f9-0d0e28eb2e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "iface.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
