{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3282cf45-b6e2-4691-abae-b992d50d4f80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Redis Enterprise is an enterprise-grade Redis, available both on-premises and in the cloud (on AWS, Google Cloud, or Azure). \n",
    "Redis Enterprise simplifies operations, scaling, and multi-tenancy includes many integrations (for example, Kubernetes), and provides multiple tiers of support.\n",
    "<br>Redis Enterprise offers robust vector database features, with an efficient API for vector index creation, management, distance metric selection, similarity search, and hybrid filtering. When coupled with its versatile data structures - including lists, hashes, JSON, and sets - Redis Enterprise shines as the optimal solution for crafting high-quality Large Language Model (LLM)-based applications. It embodies a streamlined architecture and exceptional performance, making it an instrumental tool for production environments.\n",
    "\n",
    "### Important use cases include:\n",
    "* __Chatbots with RAG__\n",
    "    <br>Ground chatbots in your data using Retrieval Augmented Generation (RAG) to enhance the quality of LLM responses.\n",
    "\n",
    "* __Semantic caching__\n",
    "    <br>Identify and retrieve cached LLM outputs to reduce response times and the number of requests to your LLM provider, which saves time and money.\n",
    "\n",
    "* __Recommendation systems__\n",
    "    <br>Power recommendation engines with fresh, relevant suggestions at low-latency, and point your users to the products they’re most likely to buy.\n",
    "\n",
    "* __Document Search__\n",
    "    <br>Make it easier to discover and retrieve information across documents and knowledge bases, using natural language and semantic search.\n",
    "\n",
    "# Google's Vertex AI\n",
    "Google's Vertex AI has expanded its capabilities by introducing Generative AI. This advanced technology comes with a specialized in-console studio experience, a dedicated API and Python SDK designed for deploying and managing instances of Google's powerful Gemini language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade475d-83ac-46f6-b120-73b9749cee31",
   "metadata": {},
   "source": [
    "# Lab overview & Objective\n",
    "\n",
    "In this Lab, we will implement a production-ready proof of concept by building an VSS application deployed on Google Cloud's infrastructure using Redis as a backbone.\n",
    "Here we will use a sample IMDB movies dataset, load this in Redis and finally invoke different types of search queries to get insight from this dataset.\n",
    "We will use the following libraries and frameworks:\n",
    "* Google Colab for hosting Jupyter Notebook\n",
    "* Redis Enterprise Cloud as Vector DB provider\n",
    "* redis-py Python library for Redis\n",
    "* redis-vl Python library for Vector specific tasks \n",
    "* Langchain for other vector management tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3cb31d-896a-4ddf-b442-5aa08b59f362",
   "metadata": {},
   "source": [
    "### Install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eadbd0-65ba-4461-b26a-f6f75202adb3",
   "metadata": {
    "id": "HqRohfRRZgFWtj1zYJIyvR5n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install required libraries\n",
    "!python3 -m pip -q install redis pandas\n",
    "!pip install -U git+https://github.com/RedisVentures/redisvl.git google-cloud-aiplatform langchain gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ca5271-f204-47b1-ac95-cff91c423826",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Configure Redis \n",
    "\n",
    "Here we will leverage Redis Enterprise Cloud available through the GCP marketplace. \n",
    "Please follow these steps to get the Redis Enterprise Cloud database up & running.\n",
    "* Log in to GCP Console, navigate to Marketplace and search for Redis Enterprise\n",
    "* Click on the option that displays Redis Enterprise Cloud and subscribe to this\n",
    "* The console will navigate to the Redis Enterprise Cloud URL\n",
    "* Sign up for Redis Enterprise Cloud. The system will ask for confirmation\n",
    "* Finally, create the database with your preferred region. For this exercise, an 'Essential' subscription will be sufficient. Select the Redis Stack\n",
    "* Once the DB is active, note down the URL. This will be needed for subsequent steps\n",
    "\n",
    "\n",
    "##### Alternative (In case Redis Enterprise Cloud is not configured)\n",
    "Install Redis Community edition using following link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1zTK0KXJUwzX",
   "metadata": {
    "id": "1zTK0KXJUwzX"
   },
   "outputs": [],
   "source": [
    "## Uncomment & execute the following code in case Redis Enterprise is not available\n",
    "##################################################################################\n",
    "\n",
    "# %%sh\n",
    "# curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "# echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "# sudo apt-get update  > /dev/null 2>&1\n",
    "# sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
    "# redis-stack-server --daemonize yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sjUooyI9VlAu",
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1715174597196,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "sjUooyI9VlAu"
   },
   "outputs": [],
   "source": [
    "## Update the 'host' field with the correct Redis host URL\n",
    "host = ''\n",
    "port = 17001\n",
    "password = 'admin'\n",
    "requirePass = True\n",
    "\n",
    "## For redis-stack-server, comment out the above code and uncomment the following:\n",
    "# host = 'localhost'\n",
    "# requirePass = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14dfc5-f428-4b02-b0f5-9a6e033b2213",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Create Redis connection object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4UnZUjIFVxWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1715174602491,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "4UnZUjIFVxWA",
    "outputId": "9afbe061-d112-46ec-f887-fc731c13bf72"
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "if requirePass:\n",
    "    client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
    "else:\n",
    "    client = redis.Redis(host = 'localhost', decode_responses=True)\n",
    "\n",
    "print(client.ping())\n",
    "# Clear Redis database (optional)\n",
    "client.flushdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3575a83-7bb1-44d8-9c6a-6b912207702e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Authenticate with GCP & set project id and region\n",
    "We will be using Vertex AI Embedding model to create embeddings for our dataset. Before doing that we must authenticate with GCP and get the suitable Google Project Id and Region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_38Ye7niWPZR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1715174607085,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "_38Ye7niWPZR",
    "outputId": "12d50424-e8be-4c1f-ecad-7461a572ed14"
   },
   "outputs": [],
   "source": [
    "## Authenticate with GCP & set project id and region\n",
    "from google.colab import auth\n",
    "from getpass import getpass\n",
    "\n",
    "auth.authenticate_user()\n",
    "print('Authenticated')\n",
    "\n",
    "# input your GCP project ID and region for Vertex AI\n",
    "PROJECT_ID = 'central-beach-194106' #getpass(\"PROJECT_ID:\")\n",
    "REGION = 'asia-south1' #input(\"REGION:\")\n",
    "\n",
    "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eefca29-7d01-49b9-b454-311c495ae780",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Download the sample dataset\n",
    "We will be using a sample IMDB Movies dataset available from Kaggle.\n",
    "Next, we will load it into Pandas Dataframe and investigate the column and its data-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnEl0UcxWV5w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1715174612680,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "cnEl0UcxWV5w",
    "outputId": "622f3ee2-1651-4592-87a3-5f4fe6b1d84a"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/abhi-data-2024/MOVIES.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-B_EHwP7ouXf",
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1715183293946,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "-B_EHwP7ouXf"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('MOVIES.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eKd397MpNoF",
   "metadata": {
    "id": "0eKd397MpNoF"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hKHXwtSGwNPr",
   "metadata": {
    "id": "hKHXwtSGwNPr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create text embeddings with Vertex AI embedding model\n",
    "\n",
    "Use the Vertex AI API for text embeddings, developed by Google.\n",
    "\n",
    "Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
    "\n",
    "\n",
    "*   Semantic search: Search text ranked by semantic similarity.\n",
    "*   Recommendation: Return items with text attributes similar to the given text.\n",
    "*   Classification: Return the class of items whose text attributes are similar to the given text.\n",
    "*   Clustering: Cluster items whose text attributes are similar to the given text.\n",
    "*   Outlier Detection: Return items where text attributes are least related to the given text.\n",
    "\n",
    "The Vertex AI text-embeddings API lets you create a text embedding using Generative AI on Vertex AI. The textembedding-gecko model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6KS60C7txG5z",
   "metadata": {
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1715182749899,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "6KS60C7txG5z"
   },
   "outputs": [],
   "source": [
    "## Use the redis-vl library and select the embedding model provider as \"textembedding-gecko@003\" \n",
    "\n",
    "from redisvl.utils.vectorize import VertexAITextVectorizer\n",
    "\n",
    "vectorizer = VertexAITextVectorizer(\n",
    "    model = \"textembedding-gecko@003\",\n",
    "    api_config = {\"project_id\": PROJECT_ID, \"location\": REGION}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EWk6LVli3Ae_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "executionInfo": {
     "elapsed": 25132,
     "status": "ok",
     "timestamp": 1715183325208,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "EWk6LVli3Ae_",
    "outputId": "35706235-8132-4823-8f7b-d455bdea0afc"
   },
   "outputs": [],
   "source": [
    "## 1. Create embeddings for the 'overview' column in movies' Dataframe \n",
    "## 2. Store these embeddings in a new column 'overview_embedding' \n",
    "## 3. Finally, append this new embeddings column in the existing dataframe\n",
    "\n",
    "embeddings = vectorizer.embed_many([element for element in df['overview']])\n",
    "df.insert(len(df.columns)-1, \"overview_embedding\", embeddings)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de29db-4482-4b61-acea-0fe61fc78757",
   "metadata": {
    "id": "hKHXwtSGwNPr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Store the dataframe in Redis database\n",
    "Once done, we will move to the next part of our exercise which is creating the suitable indexes.\n",
    "We will use these indexes to build:\n",
    "* VSS queries\n",
    "* Standard search query\n",
    "* Hybrid queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_O2o-eiVlKX3",
   "metadata": {
    "id": "_O2o-eiVlKX3"
   },
   "outputs": [],
   "source": [
    "## Store the Dataframe in Redis\n",
    "import json\n",
    "\n",
    "pipeline = client.pipeline()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    redis_key = f\"doc:{index}\"\n",
    "    pipeline.json().set(redis_key, '$', row.to_dict())\n",
    "\n",
    "pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A6H_vHkrSxco",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1715183420943,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "A6H_vHkrSxco",
    "outputId": "ba0890c3-080e-4089-b4ab-6f8e6d8ba20a"
   },
   "outputs": [],
   "source": [
    "## Verify of the record is presentin Redis\n",
    "print(client.json().get('doc:4', '$.overview_embedding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a2cd7-9f59-4b69-8db5-d0b1ab31e8b4",
   "metadata": {
    "id": "hKHXwtSGwNPr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create Indexes in Redis \n",
    "Now is the time to query Redis database. For that we will create few indexes using __redis-vl__ Python library.\n",
    "<br>Redis offers an enhanced Redis experience via the following search and query features:\n",
    "\n",
    "* A rich query language\n",
    "* Incremental indexing on JSON and hash documents\n",
    "* Vector search\n",
    "* Full-text search\n",
    "* Geospatial queries\n",
    "* Aggregations\n",
    "* You can find a complete list of features here: https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/\n",
    "\n",
    "The search and query features of Redis Stack allow you to use Redis as a:\n",
    "\n",
    "* Document database\n",
    "* Vector database\n",
    "* Secondary index\n",
    "* Search engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xaHEwARC1XrT",
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1715183431828,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "xaHEwARC1XrT"
   },
   "outputs": [],
   "source": [
    "## create index using redis-vl Python library.\n",
    "\n",
    "from redisvl.schema import IndexSchema\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "\n",
    "index_name = \"idx_movie\"\n",
    "\n",
    "schema = IndexSchema.from_dict({\n",
    "  \"index\": {\n",
    "    \"name\": index_name,\n",
    "    \"prefix\": \"doc:\",\n",
    "    \"storage_type\": \"json\"\n",
    "  },\n",
    "  \"fields\": [\n",
    "    {\n",
    "        \"name\": \"budget\",\n",
    "        \"type\": \"numeric\",\n",
    "        \"attrs\": {\n",
    "            \"sortable\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"original_title\",\n",
    "        \"type\": \"text\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"overview\",\n",
    "        \"type\": \"text\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"revenue\",\n",
    "        \"type\": \"numeric\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"vote_count\",\n",
    "        \"type\": \"numeric\",\n",
    "        \"attrs\": {\n",
    "            \"sortable\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"popularity\",\n",
    "        \"type\": \"numeric\",\n",
    "        \"attrs\": {\n",
    "            \"sortable\": True\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"overview_embedding\",\n",
    "        \"type\": \"vector\",\n",
    "        \"attrs\": {\n",
    "            \"dims\": vectorizer.dims,\n",
    "            \"distance_metric\": \"cosine\",\n",
    "            \"algorithm\": \"flat\",\n",
    "            \"datatype\": \"float32\"\n",
    "        }\n",
    "    }\n",
    "  ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "npCpJyW8av_m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1715183436309,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "npCpJyW8av_m",
    "outputId": "9f05b478-170b-4d9f-fcf7-df663f177d32"
   },
   "outputs": [],
   "source": [
    "print(vectorizer.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E8xbI7kj5MxN",
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1715183439008,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "E8xbI7kj5MxN"
   },
   "outputs": [],
   "source": [
    "# Create an index from schema and the client\n",
    "index = SearchIndex(schema, client)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Sos3lmPTDG8_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1537,
     "status": "ok",
     "timestamp": 1715183443536,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "Sos3lmPTDG8_",
    "outputId": "615c840e-da36-4b58-a1cd-dacb1631b738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: rvl\n",
      "zsh:1: command not found: rvl\n"
     ]
    }
   ],
   "source": [
    "## redis-rvl library also provides CLI support as well. You can get the information of created indexes using following commands\n",
    "\n",
    "!rvl index listall\n",
    "\n",
    "!# inspect the index fields\n",
    "!rvl index info -i idx_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeab0db-b743-4580-a473-536601785375",
   "metadata": {
    "id": "hKHXwtSGwNPr",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Querying Redis \n",
    "Now is the time to query Redis database. Again we will use __redis-vl__ Python library to achieve this.\n",
    "<br>We will invoke following types of queries against our records present in Redis:\n",
    "\n",
    "* VSS queries\n",
    "* Standard search query\n",
    "* Hybrid queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hWNrbYuzDaMA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1715184915615,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "hWNrbYuzDaMA",
    "outputId": "76eb2a31-fcd4-4e91-9895-f4e5c0dd72f5"
   },
   "outputs": [],
   "source": [
    "\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.query.filter import Num\n",
    "\n",
    "query = \"romantic movie\"\n",
    "\n",
    "vote_count_filter = Num(\"vote_count\") > 4000\n",
    "\n",
    "query_embedding = vectorizer.embed(query)\n",
    "\n",
    "vector_query = VectorQuery(\n",
    "    vector=query_embedding,\n",
    "    vector_field_name=\"overview_embedding\",\n",
    "    num_results=5,\n",
    "    return_fields=[\"original_title\", \"overview\", \"popularity\", \"revenue\", \"vote_count\"],\n",
    "    return_score=True,\n",
    "    filter_expression=vote_count_filter\n",
    ")\n",
    "\n",
    "# show the raw redis query\n",
    "str(vector_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bpsV53qbFUXI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1715184918023,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "bpsV53qbFUXI",
    "outputId": "c828784c-9552-4c95-a50d-b66c54e0a11b"
   },
   "outputs": [],
   "source": [
    "# execute the query with RedisVL\n",
    "print(json.dumps(index.query(vector_query), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WP4WFC8EGy9Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1715184430381,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "WP4WFC8EGy9Z",
    "outputId": "5331212a-f0f8-4948-c617-19718082bc81"
   },
   "outputs": [],
   "source": [
    "!rvl stats -i idx_movie"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "abhishek.srivastava (May 8, 2024, 9:14:08 AM)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
