{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bestarch/Redis-Workshops/blob/main/11-LLM_GCP_Workshop/GCP_GenAI_demo_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "id": "HqRohfRRZgFWtj1zYJIyvR5n",
      "metadata": {
        "tags": [],
        "id": "HqRohfRRZgFWtj1zYJIyvR5n"
      },
      "source": [
        "!pwd\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Install required libraries\n",
        "!python3 -m pip -q install redis\n",
        "!pip install -U langchain gradio\n",
        "!pip install -U langchain-core\n",
        "!pip install -U langchain-google-vertexai\n",
        "!pip install -U langchain-community\n",
        "%pip install -qU pypdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Update the 'host' field with the correct Redis host URL\n",
        "host = 'redis-16533.c259.us-central1-2.gce.redns.redis-cloud.com'\n",
        "port = 16533\n",
        "password = 'admin'\n",
        "requirePass = True\n"
      ],
      "metadata": {
        "id": "sjUooyI9VlAu"
      },
      "id": "sjUooyI9VlAu",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "\n",
        "if requirePass:\n",
        "    client = redis.Redis(host = host, port=port, decode_responses=True, password=password)\n",
        "else:\n",
        "    client = redis.Redis(host = 'localhost', decode_responses=True)\n",
        "\n",
        "print(client.ping())\n",
        "# Clear Redis database (optional)\n",
        "client.flushdb()\n",
        "\n",
        "REDIS_URL = f\"redis://:{password}@{host}:{port}\"\n",
        "INDEX_NAME = f\"idx_qna\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UnZUjIFVxWA",
        "outputId": "b9c1b5f7-3ed7-41d0-c3bf-39486a9abb76"
      },
      "id": "4UnZUjIFVxWA",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/abhi-data-2024/how_india_shops_online.pdf -O report.pdf\n"
      ],
      "metadata": {
        "id": "cnEl0UcxWV5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7724302c-2a67-4c99-a371-5cc43e6f53aa"
      },
      "id": "cnEl0UcxWV5w",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-15 11:16:41--  https://storage.googleapis.com/abhi-data-2024/how_india_shops_online.pdf\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.207, 64.233.181.207, 173.194.193.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13218601 (13M) [application/pdf]\n",
            "Saving to: ‘report.pdf’\n",
            "\n",
            "report.pdf          100%[===================>]  12.61M  4.30MB/s    in 2.9s    \n",
            "\n",
            "2025-01-15 11:16:46 (4.30 MB/s) - ‘report.pdf’ saved [13218601/13218601]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "#from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "file = \"report.pdf\"\n",
        "\n",
        "# set up the file loader/extractor and text splitter to create chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2500, chunk_overlap=50, add_start_index=True\n",
        ")\n",
        "\n",
        "loader = PyPDFLoader(file)\n",
        "documents = loader.load()\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "#chunked_docs = [doc.page_content for doc in chunks]"
      ],
      "metadata": {
        "id": "-B_EHwP7ouXf"
      },
      "id": "-B_EHwP7ouXf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunked_docs = [doc.page_content for doc in chunks]\n",
        "print(len(chunks))\n",
        "print(len(chunked_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrUStfXjniIa",
        "outputId": "67d1c52b-6b86-432a-b383-9ad556b95042"
      },
      "id": "YrUStfXjniIa",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from google.colab import auth\n",
        "from getpass import getpass\n",
        "import vertexai\n",
        "import google.auth\n",
        "import vertexai\n",
        "\n",
        "# input your GCP project ID and region for Vertex AI\n",
        "PROJECT_ID = getpass(\"PROJECT_ID:\")\n",
        "REGION = 'us-central1' #input(\"REGION:\")\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "#creds, _ = google.auth.default(quota_project_id=PROJECT_ID)\n",
        "print('Authenticated')\n",
        "\n",
        "#vertexai.init(project=PROJECT_ID, credentials=creds, location=REGION)\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "print(f'PROJECT_ID: {PROJECT_ID} & REGION: {REGION}')\n",
        "\n"
      ],
      "metadata": {
        "id": "eWsh85l_sRvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5e57c1-9c2b-45da-d176-a25457997cc3"
      },
      "id": "eWsh85l_sRvp",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_ID:··········\n",
            "Authenticated\n",
            "PROJECT_ID: central-beach-194106 & REGION: us-central1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create text embeddings with Vertex AI embedding model\n",
        "\n",
        "Use the Vertex AI API for text embeddings, developed by Google.\n",
        "\n",
        "Text embeddings are a dense vector representation of a piece of content such that, if two pieces of content are semantically similar, their respective embeddings are located near each other in the embedding vector space. This representation can be used to solve common NLP tasks, such as:\n",
        "\n",
        "\n",
        "*   Semantic search: Search text ranked by semantic similarity.\n",
        "*   Recommendation: Return items with text attributes similar to the given text.\n",
        "*   Classification: Return the class of items whose text attributes are similar to the given text.\n",
        "*   Clustering: Cluster items whose text attributes are similar to the given text.\n",
        "*   Outlier Detection: Return items where text attributes are least related to the given text.\n",
        "\n",
        "The Vertex AI text-embeddings API lets you create a text embedding using Generative AI on Vertex AI. The textembedding-gecko model accepts a maximum of 3,072 input tokens (i.e. words) and outputs 768-dimensional vector embeddings."
      ],
      "metadata": {
        "id": "hKHXwtSGwNPr"
      },
      "id": "hKHXwtSGwNPr"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.redis import Redis\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n",
        "\n",
        "def get_vectordb() -> Redis:\n",
        "    \"\"\"Create the Redis vectordb.\"\"\"\n",
        "    # Load Redis with documents\n",
        "    vectordb = Redis.from_documents(\n",
        "        documents=chunks,\n",
        "        embedding=embeddings,\n",
        "        index_name=INDEX_NAME,\n",
        "        redis_url=REDIS_URL\n",
        "    )\n",
        "    return vectordb\n",
        "\n",
        "\n",
        "redis = get_vectordb()\n",
        "\n",
        "#embedder = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n"
      ],
      "metadata": {
        "id": "A6H_vHkrSxco"
      },
      "id": "A6H_vHkrSxco",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Include RAG\n",
        "\n",
        "We're going to build a complete RAG pipeline from scratch incorporating the following components:\n",
        "\n",
        "Standard retrieval and chat completion\n",
        "Dense content representation to improve accuracy\n",
        "Query re-writing to improve accuracy\n",
        "Semantic caching to improve performance\n",
        "Conversational session history to improve personalization"
      ],
      "metadata": {
        "id": "kVJdyD1OVYE-"
      },
      "id": "kVJdyD1OVYE-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Prompt template\n",
        "PromptTemplate defines the exect text of the response that would be fed to the LLM. This step is optional, but the defaults usually work well for OpenAI and might fall short for other models."
      ],
      "metadata": {
        "id": "aNtLTGcvR-IS"
      },
      "id": "aNtLTGcvR-IS"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function to define prompt template\n",
        "\n",
        "def create_prompt():\n",
        "    \"\"\"Create the QA chain.\"\"\"\n",
        "    from langchain.prompts import PromptTemplate\n",
        "    from langchain.chains import RetrievalQA\n",
        "\n",
        "    # Define our prompt\n",
        "    prompt_template = \"\"\"Use only the following pieces of context to answer the question. If you don't know the answer, say that you don't know, don't try to make up an answer.\n",
        "\n",
        "    This should be in the following format:\n",
        "\n",
        "    Question: [question here]\n",
        "    Answer: [answer here]\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    Context:\n",
        "    ---------\n",
        "    {context}\n",
        "    ---------\n",
        "    Question: {question}\n",
        "    Answer:\"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        template=prompt_template,\n",
        "        input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "BCtEFE8ziT5d"
      },
      "id": "BCtEFE8ziT5d",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Invoke Google Vertex LLM using Langchain\n",
        "# This is where the Langchain brings all the components together in a form of a simple QnA chain\n",
        "from langchain_google_vertexai import VertexAI\n",
        "from langchain.cache import RedisSemanticCache\n",
        "from langchain.globals import set_llm_cache\n",
        "\n",
        "llm = VertexAI(\n",
        "    model_name=\"gemini-1.5-pro-002\",\n",
        "    max_output_tokens=2048,\n",
        "    temperature=0.5,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Semantic cache\n",
        "set_llm_cache(\n",
        "    RedisSemanticCache(redis_url=REDIS_URL, embedding=embeddings, score_threshold=0.05)\n",
        ")\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=redis.as_retriever(search_type=\"similarity_distance_threshold\",search_kwargs={\"distance_threshold\":0.5}),\n",
        "    #return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": create_prompt()},\n",
        "    #verbose=True\n",
        "    )"
      ],
      "metadata": {
        "id": "DYtdUxxFSxh9"
      },
      "id": "DYtdUxxFSxh9",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "qa.invoke('What may be some motivations for shopping online?')['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "XelSUbTkS7rj",
        "outputId": "119cd47e-1777-41e5-ed47-a391d3bbf98b"
      },
      "id": "XelSUbTkS7rj",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.5 ms, sys: 2.86 ms, total: 19.4 ms\n",
            "Wall time: 425 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: What are some motivations for shopping online?\\nAnswer: Some motivations for online shopping include wider range of price options and brands, absence of physical stores for premium brands, stockouts of certain products, lack of knowledgeable staff in offline stores, lack of discounts and special offers in physical stores, large crowds in malls during weekends, and browsing through online shopping platforms during free time.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "qa.invoke('How do Indians like to pay for shopping online?')['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "B2f9CC3JI2BL",
        "outputId": "c8c2f492-38ba-4dc2-caeb-7461e0561c7e"
      },
      "id": "B2f9CC3JI2BL",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 322 ms, sys: 3.95 ms, total: 326 ms\n",
            "Wall time: 797 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Question: How do Indians like to pay for shopping online?\\nAnswer: Urban dwellers and rest of India consumers show similar acceptance levels for UPI payments. However, cash on delivery (CoD) is still preferred among rest of India consumers to minimize fraud risk.  While UPI is gaining popularity due to convenience, speed, and security, concerns about online platforms and payment methods persist, especially among rest of India consumers.  Rest of India's Generation X prefers card transactions for mid-high value purchases on well-known platforms because of the direct link to bank accounts and perceived transaction safety. Paytm is popular among urban dwellers for its user-friendly wallet, while PhonePe is preferred by rest of India for its intuitive interface. Google Pay ranks second nationwide.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "qa.invoke('What are some known challenges in shopping online?')['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "LLHoWVshJJHK",
        "outputId": "acb8a980-3708-4554-fef8-0a27765a41bb"
      },
      "id": "LLHoWVshJJHK",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 19.2 ms, sys: 277 µs, total: 19.5 ms\n",
            "Wall time: 634 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: What are some known challenges in shopping online?\\nAnswer: Some challenges include payment fraud, credibility of unfamiliar websites, doubts about product quality matching images, and inconsistent delivery experiences.  Specifically, urban deliveries face logistical overload, regulations, and access restrictions leading to inconsistent experiences, while timing of deliveries often clashes with fast-paced urban lifestyles.  Additionally, fake reviews, particularly for health and wellness products, deter purchases.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa.invoke('How home and kitchen segment is growing?')['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5PVFYBW1NNKm",
        "outputId": "7e1e0cd7-3c24-4d5a-a718-d78112c29dbb"
      },
      "id": "5PVFYBW1NNKm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: How home and kitchen segment is growing?\\nAnswer: In the Indian market, the home furnishing and kitchen sector is growing at a CAGR of 10%. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa.invoke('What are the effects of social media on online shopping?')['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "bgfyRlzCNquj",
        "outputId": "6f6970fc-5467-4bd7-fa90-74997301ab4a"
      },
      "id": "bgfyRlzCNquj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer: Social media has amplified awareness and aspirations of products. 62% of respondents tried products after seeing them on Facebook and Instagram. Social media is the most preferred channel for encouraging trials of new products. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa.invoke('What are some relevant items that are shopped online?')['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xClDk__XHFw-",
        "outputId": "df24cd18-7e3e-47ff-f591-15a38898a2ca"
      },
      "id": "xClDk__XHFw-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    Answer: Grocery, Fashion and Accessories, Electronics and Consumer Durables, Beauty and Personal Care, Health and Wellness, Home and Kitchen, Sports and Fitness \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def handle(query):\n",
        "    start_time = time.time()\n",
        "    response = qa.run(query)\n",
        "    end_time = time.time()\n",
        "    processing_time = end_time - start_time\n",
        "    return response, f\"Time: {processing_time:.2f} secs\"\n",
        "\n",
        "iface = gr.Interface(fn=handle, inputs=\"text\", outputs=[\n",
        "        gr.Textbox(label=\"Response\"),\n",
        "        gr.Textbox(label=\"Time\")\n",
        "    ], title=\"How India shops online?\")\n",
        "iface.launch(share=True)"
      ],
      "metadata": {
        "id": "UmsYlwP9XZ2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "627eb44a-ccef-4b86-e0e5-c4518c90baeb"
      },
      "id": "UmsYlwP9XZ2G",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://267dd78b9ddf449db9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://267dd78b9ddf449db9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvmnrq_3YY6p",
        "outputId": "2eecf130-23be-4791-e8f9-0d0e28eb2e7d"
      },
      "id": "nvmnrq_3YY6p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}